<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Solving Automated App Navigation: A Use-case - Nauman Mustafa</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="./style.css">
</head>
<body>
    <div class="theme-toggle" id="theme-toggle">
        <i class="fas fa-sun"></i>
        <span>Dark Mode</span>
    </div>
    
    <div class="container">
        <header class="hero">
            <div class="hero-content">
                <a href="https://nocode.autify.com/blog/solving-automated-app-navigation-a-use-case" target="_blank" class="original-post-link">
                    <i class="fas fa-external-link-alt"></i>
                    <span>Read Original on Autify Blog</span>
                </a>
                
                <h1 class="hero-title">Solving Automated App Navigation: A Use-case</h1>
                <h2 class="hero-subtitle">Using AI to intelligently navigate through mobile applications</h2>
                
                <div class="hero-meta">
                    <div class="meta-item">
                        <i class="fas fa-building"></i>
                        <span>Autify</span>
                    </div>
                    <div class="meta-item">
                        <i class="fas fa-calendar"></i>
                        <span>July 25, 2021</span>
                    </div>
                    <div class="meta-item">
                        <i class="fas fa-clock"></i>
                        <span>8 min read</span>
                    </div>
                </div>
            </div>
        </header>
        
        <main>
            <a href="../" class="back-link">
                <i class="fas fa-arrow-left"></i>
                <span>Back to Home</span>
            </a>
            
            <article class="article">
                <div class="intro-section">
                    <h2>Introduction</h2>
                    <p>We at Autify solve a lot of pain points for our customers. One of the core components of our product is to help customers record, manage and periodically test user scenarios of their web and mobile applications. With the recent success of AI in automating the very process of automation, we have been trying to accelerate recording user scenarios using reinforcement learning – internally called scenario generation. The goal is to intelligently navigate through the app and find all the possible user flows and potential bugs along the way.</p>
                    
                    <p>In this article, we will show how we tried different techniques for behavior cloning. Behavior cloning is a very simple form of reinforcement learning where an AI system learns to mimic or clone the behavior of an expert. In our case, a human navigates through different app screens, and this is then fed to a behavior cloning system to mimic the behavior.</p>
                </div>

                <div class="navigation-challenge-box">
                    <h3>
                        <i class="fas fa-robot"></i>
                        The Navigation Challenge
                    </h3>
                    <p>How do you teach an AI to navigate mobile apps like a human? The challenge lies in <strong>predicting tap locations</strong> on screens with complex UI elements, varying layouts, and contextual relationships between different app states.</p>
                </div>

                <p>To accelerate experimentation and development, we created a toy environment that mimics some aspects of the complexity of the main problem. In this article, we will primarily use this toy environment to model the original problem as well as try to solve it.</p>
                
                <p>We model our problem as predicting tap location on the screen. So, the primary objective is to click/tap on different locations to navigate to new screens. We needed to figure out which neural network architecture can predict x, y coordinates directly from the image. While the input may be much more complex for the real problem, like press and hold or drag, we use only tapping to simplify the problem. This article will go into some of the technical details on how we solved this problem of predicting coordinates from images.</p>

                <h2>The Toy Problem</h2>
                
                <p>Imagine a game where we have to click on the circle out of so many other shapes. This is exactly what the toy environment represents. Each image is like a mobile screenshot where we have to click on the circle. Let look at some of the images from the toy environment.</p>
                
                <div class="image-container">
                    <img src="./i1.png" alt="Environment Demo" class="demo-image">
                    <div class="image-caption">Sample images from the toy environment showing circles among various rectangles</div>
                </div>
                
                <div class="toy-problem-analysis">
                    <div class="challenge-card">
                        <div class="challenge-header">
                            <i class="fas fa-search"></i>
                            <h4>The Challenge</h4>
                        </div>
                        <div class="challenge-content">
                            <p>This environment generates a random number of random-sized and random colored rectangles and places only one circle. The goal of the model is to predict the coordinates of the circle.</p>
                            <div class="difficulty-factors">
                                <div class="factor-item">
                                    <i class="fas fa-palette"></i>
                                    <span>Color variations make shape detection difficult</span>
                                </div>
                                <div class="factor-item">
                                    <i class="fas fa-expand-arrows-alt"></i>
                                    <span>Random sizes create scale challenges</span>
                                </div>
                                <div class="factor-item">
                                    <i class="fas fa-shapes"></i>
                                    <span>Must rely on shape, not color information</span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <p>As you can see, it is sometimes tough to distinguish the circle from the rectangle because of the size and the color variations. Now the goal of the model is not to rely on the color information but rather shape information of the objects and output the coordinate.</p>
                
                <p>Two approaches come to mind when modeling this problem. The first one is to predict a probability/heat map that shows where to click (it outputs an entire image), and the second one is to simply predict x,y as directly from the neural network (regression model: it outputs just two numbers).</p>

                <div class="approach-comparison">
                    <div class="approach-card regression">
                        <div class="approach-header">
                            <i class="fas fa-chart-line"></i>
                            <h4>Regression Approach</h4>
                        </div>
                        <div class="approach-content">
                            <p>Directly predict (x, y) coordinates</p>
                            <div class="pros-cons">
                                <div class="pros">
                                    <h5><i class="fas fa-check"></i> Pros</h5>
                                    <ul>
                                        <li>Simple and fast</li>
                                        <li>Minimal output</li>
                                        <li>Direct optimization</li>
                                    </ul>
                                </div>
                                <div class="cons">
                                    <h5><i class="fas fa-times"></i> Limitations</h5>
                                    <ul>
                                        <li>Single target assumption</li>
                                        <li>No uncertainty modeling</li>
                                        <li>Overfitting issues</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="vs-divider">
                        <span>VS</span>
                    </div>
                    
                    <div class="approach-card heatmap">
                        <div class="approach-header">
                            <i class="fas fa-fire"></i>
                            <h4>Heatmap Approach</h4>
                        </div>
                        <div class="approach-content">
                            <p>Predict probability distribution over entire image</p>
                            <div class="pros-cons">
                                <div class="pros">
                                    <h5><i class="fas fa-check"></i> Pros</h5>
                                    <ul>
                                        <li>Handles multiple targets</li>
                                        <li>Models uncertainty</li>
                                        <li>Better generalization</li>
                                    </ul>
                                </div>
                                <div class="cons">
                                    <h5><i class="fas fa-times"></i> Limitations</h5>
                                    <ul>
                                        <li>More complex</li>
                                        <li>Larger output space</li>
                                        <li>Computationally expensive</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <h2>The Regression Model</h2>
                
                <p>Assuming there is only one circle to predict (which we will show later that the assumption is not sufficient for the real problem), we decided that predicting the entire heatmap might be overkill. So the fastest route seemed like to go with the regression model. We designed the model to predict the mean and the log of standard deviation for the regression head (not just x,y but also width & height), allowing the model to represent some level of uncertainty. After training for a few iterations, we get excellent predictions using this approach:</p>
                
                <div class="image-container">
                    <img src="./i2.png" alt="Regression Output" class="result-image">
                    <div class="image-caption">Regression model output: Green lines show ground truth, red lines show predictions</div>
                </div>
                
                <p>In this output, the intersection of green lines is the ground truth (the actual center of the circle), and the intersection of red lines is the coordinate values predicted by the model. As we can see, it is very, very close to the actual output. If we look at the loss curve, we can see it converges very well:</p>
                
                <div class="image-container">
                    <img src="./i3.png" alt="Regression Loss" class="loss-curve">
                    <div class="image-caption">Loss curve showing excellent convergence for single circle prediction</div>
                </div>

                <div class="insight-box success">
                    <h3>
                        <i class="fas fa-lightbulb"></i>
                        Initial Success
                    </h3>
                    <p><strong>Note:</strong> Since we randomly generate a new image at every step, training loss is the same as validation or testing loss because no two images will ever be the same even in training data.</p>
                </div>
                
                <p>But when we applied this model to our real problem containing mobile screenshots and their coordinates, it simply failed by overfitting training data and always predicting 0.5,0.5 for the validation data. Further investigation revealed that the toy problem is not sufficiently modeling the true problem. And the assumption we made that there should only be one point to click given a screen is false.</p>

                <h2>The Improved Toy Problem</h2>
                
                <p>Based on the analysis, we update the toy problem: generation of random sized & random colored rectangles is the same. However, now there can be (minimum 1 but) up to 5 circles on the image simultaneously. And one of them is randomly selected to be the prediction output. Here is sample output from the new environment:</p>
                
                <div class="image-container">
                    <img src="./i4.png" alt="Improved Toy Problem" class="demo-image">
                    <div class="image-caption">Updated toy environment with multiple circles (1-5 per image)</div>
                </div>

                <div class="problem-evolution">
                    <div class="evolution-step">
                        <div class="step-number">1</div>
                        <div class="step-content">
                            <h4>Original Problem</h4>
                            <p>Single circle per image</p>
                            <div class="step-result success">✓ Model converged well</div>
                        </div>
                    </div>
                    <div class="evolution-arrow">→</div>
                    <div class="evolution-step">
                        <div class="step-number">2</div>
                        <div class="step-content">
                            <h4>Real-world Application</h4>
                            <p>Mobile app screenshots</p>
                            <div class="step-result failure">✗ Model failed (0.5, 0.5)</div>
                        </div>
                    </div>
                    <div class="evolution-arrow">→</div>
                    <div class="evolution-step">
                        <div class="step-number">3</div>
                        <div class="step-content">
                            <h4>Improved Problem</h4>
                            <p>Multiple circles (1-5 per image)</p>
                            <div class="step-result challenge">? Testing required</div>
                        </div>
                    </div>
                </div>
                
                <p>After training the same regression model for this updated toy problem, the model did not converge. Here is the output of this model compared with ground truth:</p>
                
                <div class="image-container">
                    <img src="./i5.png" alt="Regression Output on Improved Problem" class="result-image">
                    <div class="image-caption">Regression model struggles with multiple circles - poor prediction accuracy</div>
                </div>
                
                <p>The loss curve clearly indicates that the model cannot learn further despite running for 4x the iterations. For comparison, the red loss curve is for the previous run when there was only one circle, and blue is for this run:</p>
                
                <div class="image-container">
                    <img src="./i6.png" alt="Regression Loss on Updated Problem" class="loss-curve">
                    <div class="image-caption">Loss comparison: Red (single circle) vs Blue (multiple circles) - clear divergence</div>
                </div>

                <div class="insight-box warning">
                    <h3>
                        <i class="fas fa-exclamation-triangle"></i>
                        Critical Discovery
                    </h3>
                    <p>Comparing this (blue) loss curve with one when training on the real problem was similar; however, in the case of training on the real problem, validation loss started to rise, and the model completely overfitted the data; Thus, training diverged.</p>
                </div>
                
                <p>We also explored a model with multiple regression output heads to predict multiple output points. We modeled it as the most optimistic loss, i.e., the minimum distance from the output would be considered for the loss. However, this did not converge either.</p>

                <h2>A Better Model?</h2>
                
                <p>We realized that the regression method could not properly model the required uncertainty for solving this problem. Thus, we switched to predicting heatmap/probability using U²Net. We converted x,y coordinates to a black image with a white circle of a small radius at that location. At the start, the network predicted all the circles and rectangles. Here is an output from early in training:</p>
                
                <div class="image-container">
                    <img src="./i7.png" alt="Early Output for Heatmap Generation" class="result-image">
                    <div class="image-caption">Early heatmap training: Top row shows input, middle shows model output, bottom shows ground truth</div>
                </div>
                
                <p>In this image, the top row shows the generated images, the images in the middle row are the outputs by the model, and the bottom row is the ground truth, i.e., what the model should output. As training progresses, the model learns to distinguish circles from rectangles and outputs only the locations of circles as those are the ones that matter:</p>
                
                <div class="image-container">
                    <img src="./i8.png" alt="Converged Heatmap" class="result-image">
                    <div class="image-caption">Converged heatmap model: Successfully identifies all circles while filtering out rectangles</div>
                </div>

                <div class="breakthrough-box">
                    <h3>
                        <i class="fas fa-star"></i>
                        Extraordinary Discovery
                    </h3>
                    <p>As you can see – while we ask the model to predict one of the circles – since the model is unsure which one, it is actually predicting the locations of <strong>all circles</strong>. This is something extraordinary as the neural network not only predicts the correct output but also <strong>filters out the training noise</strong>. Thus generalizing far beyond the original objective.</p>
                </div>
                
                <p>Loss curve also indicates model convergence:</p>
                
                <div class="image-container">
                    <img src="./i9.png" alt="Heatmap Loss" class="loss-curve">
                    <div class="image-caption">Heatmap model loss curve showing successful convergence</div>
                </div>

                <div class="insight-box info">
                    <h3>
                        <i class="fas fa-info-circle"></i>
                        Technical Note
                    </h3>
                    <p><strong>Note:</strong> This loss curve cannot be compared to the loss curve of regression models as this is binary cross-entropy loss and previously we used mean squared error loss.</p>
                </div>
                
                <p>When we applied this model to our main objective of modeling tap locations on mobile screenshots, it did not overfit and generalize very well. Here is a screenshot of the output of our model for an android app (interestingly, the model was trained on iOS screenshots):</p>
                
                <div class="image-container">
                    <img src="./i10.png" alt="Real Example" class="real-world-result">
                    <div class="image-caption">Real-world application: Model successfully identifies clickable elements on Android app (trained on iOS)</div>
                </div>

                <h2>Conclusion</h2>
                
                <p>In conclusion, we show that using a smaller and simplified version of a very complex problem can help accelerate the experimentation in machine learning. We also show that bad assumptions can oversimplify the problem and thus fail to model the intended objective. We also demonstrate that a good model which can represent uncertainty should be able to reduce the effect of training noise and overall improve generalization.</p>

                <div class="key-learnings">
                    <h3>
                        <i class="fas fa-graduation-cap"></i>
                        Key Learnings
                    </h3>
                    <div class="learning-grid">
                        <div class="learning-item">
                            <i class="fas fa-flask"></i>
                            <h5>Toy Problems Are Valuable</h5>
                            <p>Simplified environments can accelerate ML experimentation, but must capture essential complexity</p>
                        </div>
                        <div class="learning-item">
                            <i class="fas fa-exclamation-triangle"></i>
                            <h5>Assumptions Matter</h5>
                            <p>Bad assumptions (single click point) can oversimplify and fail to model real objectives</p>
                        </div>
                        <div class="learning-item">
                            <i class="fas fa-balance-scale"></i>
                            <h5>Uncertainty Modeling</h5>
                            <p>Models that represent uncertainty can reduce training noise and improve generalization</p>
                        </div>
                        <div class="learning-item">
                            <i class="fas fa-magic"></i>
                            <h5>Emergent Behavior</h5>
                            <p>Neural networks can exceed objectives, filtering noise and generalizing beyond training scope</p>
                        </div>
                    </div>
                </div>
                
                <p>Finally, we are working hard on this feature. Stay tuned for future updates. And if you have any questions, feel free to reach out to us on Twitter @AutifyHQ.</p>

                <div class="contact-section">
                    <h3>
                        <i class="fas fa-rocket"></i>
                        Future of Automated Testing
                    </h3>
                    <p>This work represents a significant step toward fully automated app testing. The ability to intelligently navigate applications opens up possibilities for comprehensive test coverage, bug discovery, and quality assurance at scale.</p>
                    <div class="social-links">
                        <a href="https://twitter.com/AutifyHQ" target="_blank" class="social-link">
                            <i class="fab fa-twitter"></i>
                            <span>Follow @AutifyHQ</span>
                        </a>
                    </div>
                </div>

                <div class="tags-section">
                    <h3>
                        <i class="fas fa-tags"></i>
                        Topics
                    </h3>
                    <div class="tags">
                        <span class="tag">Machine Learning</span>
                        <span class="tag">Behavior Cloning</span>
                        <span class="tag">Reinforcement Learning</span>
                        <span class="tag">Computer Vision</span>
                        <span class="tag">Automated Testing</span>
                        <span class="tag">Mobile App Testing</span>
                        <span class="tag">Neural Networks</span>
                        <span class="tag">U²Net</span>
                    </div>
                </div>
            </article>
            
            <a href="../" class="back-link">
                <i class="fas fa-arrow-left"></i>
                <span>Back to Home</span>
            </a>
        </main>
        
        <footer class="footer">
            <p>&copy; 2025 Nauman Mustafa. All rights reserved.</p>
        </footer>
    </div>
    
    <script src="/lib/shared.js"></script>
</body>
</html> 